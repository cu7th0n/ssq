{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3D.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cu7th0n/ssq/blob/master/3D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "_JvtbCsfIs4q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df09b048-5009-4c59-92d2-4494118fa96b"
      },
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import xlwt\n",
        "import time\n",
        "\n",
        "#获取第一页的内容\n",
        "def get_one_page(url):\n",
        "    headers = {\n",
        "        'User-Agent':'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.140 Safari/537.36'\n",
        "    }\n",
        "    response = requests.get(url,headers=headers)\n",
        "    if response.status_code == 200:\n",
        "        return response.text\n",
        "    return \n",
        "\n",
        "#解析第一页内容，数据结构化\n",
        "def parse_one_page(html):\n",
        "\n",
        "    soup = BeautifulSoup(html,'lxml')\n",
        "    i = 0\n",
        "    for item in soup.select('tr')[2:-1]:\n",
        "\n",
        "        yield{\n",
        "            'time':item.select('td')[i].text,\n",
        "            'digit_1':item.select('td em')[0].text,\n",
        "            'digit_2':item.select('td em')[1].text,\n",
        "            'digit_3':item.select('td em')[2].text\n",
        "        }\n",
        "\n",
        "#将数据写入Excel表格中\n",
        "def write_to_excel():\n",
        "    f = xlwt.Workbook()                             \n",
        "    sheet1 = f.add_sheet('ssq',cell_overwrite_ok=True)\n",
        "    row0 = [\"date\",\"digit_1\",\"digit_2\",\"digit_3\"]\n",
        "    #写入第一行\n",
        "    for j in range(0,len(row0)):\n",
        "        sheet1.write(0,j,row0[j])\n",
        "\n",
        "    #依次爬取每一页内容的每一期信息，并将其依次写入Excel\n",
        "    i=0\n",
        "    for k in range(1,257):\n",
        "        url = 'http://kaijiang.zhcw.com/zhcw/html/3d/list_%s.html' %(str(k))\n",
        "        html = get_one_page(url)\n",
        "        \n",
        "        #写入每一期的信息\n",
        "        for item in parse_one_page(html):\n",
        "            sheet1.write(i+1,0,item['time'])\n",
        "            sheet1.write(i+1,1,item['digit_1'])\n",
        "            sheet1.write(i+1,2,item['digit_2'])\n",
        "            sheet1.write(i+1,3,item['digit_3'])\n",
        "            i+=1\n",
        "    \n",
        "    f.save('3d.xls')\n",
        "    print('%d页已保存。'%k)\n",
        "    \n",
        "def main():\n",
        "    write_to_excel()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "256页已保存。\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JYIeA4K5J3NM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras.models import load_model\n",
        "\n",
        "\n",
        "data = pd.read_excel('3d.xls')\n",
        "\n",
        "data['date'] = pd.to_datetime(data['date'])\n",
        "data = data.sort_values(by = 'date')\n",
        "data.reset_index(inplace=True)\n",
        "del data['index']\n",
        "del data['date']\n",
        "\n",
        "D_1 = data['digit_1']\n",
        "D_2 = data['digit_2']\n",
        "D_3 = data['digit_3']\n",
        "\n",
        "models = ['M1_model.h5', 'M2_model.h5', 'M3_model.h5']\n",
        "tdatas = [D_1, D_2, D_3]\n",
        "\n",
        "\n",
        "\n",
        "def create_interval_dataset(dataset, look_back):\n",
        "    \"\"\"\n",
        "    :param dataset: input array of time intervals\n",
        "    :param look_back: each training set feature length\n",
        "    :return: convert an array of values into a dataset matrix.\n",
        "    \"\"\"\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset) - look_back):\n",
        "        dataX.append(dataset[i:i+look_back])\n",
        "        dataY.append(dataset[i+look_back])\n",
        "    return np.asarray(dataX), np.asarray(dataY)\n",
        "\n",
        "  \n",
        "def train_model(train_set,mname,look_back = 200,data_dim = 11,batch_size = 1):\n",
        "\n",
        "  timesteps = look_back\n",
        " \n",
        "  # Expected input batch shape: (batch_size, timesteps, data_dim)\n",
        "  # Note that we have to provide the full batch_input_shape since the network is stateful.\n",
        "  # the sample of index i in batch k is the follow-up for the sample i in batch k-1.\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(data_dim, return_sequences=True, stateful=True,\n",
        "               batch_input_shape=(batch_size, timesteps, data_dim)))\n",
        "  model.add(LSTM(data_dim*2, return_sequences=True, stateful=True))\n",
        "  model.add(Dropout(0.3))\n",
        "  \n",
        "  model.add(LSTM(data_dim*4, return_sequences=True, stateful=True))\n",
        "  model.add(Dropout(0.3))\n",
        "  \n",
        "  model.add(LSTM(data_dim*8, return_sequences=True, stateful=True))\n",
        "  model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(LSTM(data_dim*8, stateful=True))\n",
        "  model.add(Dense(data_dim, activation='softmax'))\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "  df = to_categorical(train_set,data_dim)\n",
        "  \n",
        "  dataX, dataY = create_interval_dataset(df, look_back) \n",
        "  \n",
        "  total = len(train_set)\n",
        "  split = total*8//10\n",
        "\n",
        "  X_train = dataX[:split]\n",
        "  y_train = dataY[:split]\n",
        "\n",
        "  X_val = dataX[split+1:total-1]\n",
        "  y_val = dataY[split+1:total-1]\n",
        "  \n",
        "  model.fit(X_train, y_train,batch_size=batch_size, epochs=1,\n",
        "            shuffle=False,validation_data=(X_val, y_val))\n",
        "  model.save(mname)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3p4fcuL3J8VJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "122169e0-a5d2-471c-fe79-5dc5ca1bd60b"
      },
      "cell_type": "code",
      "source": [
        "look_back=300\n",
        "for (model,tdata) in zip(models,tdatas):\n",
        "  train_model(tdata,model,look_back)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4096 samples, validate on 723 samples\n",
            "Epoch 1/1\n",
            "4096/4096 [==============================] - 1401s 342ms/step - loss: 2.3308 - acc: 0.1023 - val_loss: 2.3318 - val_acc: 0.1010\n",
            "Train on 4096 samples, validate on 723 samples\n",
            "Epoch 1/1\n",
            "4096/4096 [==============================] - 1460s 356ms/step - loss: 2.3341 - acc: 0.1018 - val_loss: 2.3101 - val_acc: 0.1065\n",
            "Train on 4096 samples, validate on 723 samples\n",
            "Epoch 1/1\n",
            "4096/4096 [==============================] - 1479s 361ms/step - loss: 2.3337 - acc: 0.0981 - val_loss: 2.3313 - val_acc: 0.1079\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "px21H2tfSMES",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "e2d893d3-e7ad-433f-f1cd-8356ee53324d"
      },
      "cell_type": "code",
      "source": [
        "for (model,tdata) in zip(models,tdatas):\n",
        "    \n",
        "    print(model)\n",
        "    M_ssq = load_model(model)\n",
        "\n",
        "    test_X = to_categorical(np.asarray([tdata[-look_back:]]),num_classes=11)\n",
        "\n",
        "    pred = M_ssq.predict(test_X)\n",
        "    ranks = np.argsort(pred[0])\n",
        "    \n",
        "    for i in range(1,11):\n",
        "        print(str(ranks[-i]) + ' : %.2f%%' %(pred[0][ranks[-i]]*100))\n",
        "    print('\\n')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "M1_model.h5\n",
            "8 : 13.20%\n",
            "3 : 12.86%\n",
            "1 : 12.39%\n",
            "2 : 11.55%\n",
            "6 : 9.82%\n",
            "7 : 9.04%\n",
            "0 : 8.93%\n",
            "4 : 8.74%\n",
            "9 : 7.99%\n",
            "5 : 5.48%\n",
            "\n",
            "\n",
            "M2_model.h5\n",
            "5 : 11.47%\n",
            "8 : 10.76%\n",
            "9 : 10.72%\n",
            "0 : 10.42%\n",
            "1 : 10.25%\n",
            "4 : 10.00%\n",
            "7 : 9.99%\n",
            "6 : 9.15%\n",
            "2 : 9.00%\n",
            "3 : 8.20%\n",
            "\n",
            "\n",
            "M3_model.h5\n",
            "9 : 15.28%\n",
            "3 : 11.97%\n",
            "8 : 11.30%\n",
            "0 : 10.96%\n",
            "4 : 10.65%\n",
            "7 : 9.85%\n",
            "5 : 8.50%\n",
            "6 : 8.04%\n",
            "1 : 7.09%\n",
            "2 : 6.36%\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}